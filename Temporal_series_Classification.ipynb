{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FdqcMXk96rS"
      },
      "source": [
        "### Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxUZy3U-fjcm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_cUOiS9flQ8"
      },
      "outputs": [],
      "source": [
        "%cd /gdrive/My Drive/Colab Notebooks/Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfehjCy896Fd"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_wVYNVVfr6q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16) \n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQWEHP13tQsc"
      },
      "source": [
        "### Set seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imBtfhUPLwB-"
      },
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRK9IPIc-ZEz"
      },
      "source": [
        "### Exploration Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMysAd_I-lED"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlpb8o-Vf67x"
      },
      "outputs": [],
      "source": [
        "!unzip /gdrive/My\\ Drive/Colab\\ Notebooks/Homework\\ 2/dataset.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0m6Gn4fkm9S"
      },
      "outputs": [],
      "source": [
        "x = np.load(\"x_train.npy\")\n",
        "y = np.load(\"y_train.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BUA0KHJkm67"
      },
      "outputs": [],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAprzP2bkm4S"
      },
      "outputs": [],
      "source": [
        "# Count elements per class, checking eventual unbalance \n",
        "labels = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
        "\n",
        "for i in range(12):\n",
        "  c = np.count_nonzero(y == i)\n",
        "  print(str(i) + \": \" + str(c) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=seed, stratify=y) "
      ],
      "metadata": {
        "id": "dso5GytId2qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "4SRUB1eAeb9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LfzQzLbGGrd"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
        "X_val = scaler.transform(x_val.reshape(-1, x_val.shape[-1])).reshape(x_val.shape)"
      ],
      "metadata": {
        "id": "nC0Z4q5H99Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_0wmrz3MGsd"
      },
      "source": [
        "### Build and train models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkUqhy__KMnr"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "classes = y_train.shape[-1] \n",
        "batch_size = 128\n",
        "epochs = 1000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tfk.utils.to_categorical(y_train)\n",
        "y_val = tfk.utils.to_categorical(y_val)"
      ],
      "metadata": {
        "id": "0l5qJrBvC31Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1D Convolutional Neural Network\n"
      ],
      "metadata": {
        "id": "OKODzBDqefxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_1DCNN_classifier(input_shape, classes):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    # Feature extractor\n",
        "    cnn = tfkl.Conv1D(512,3,padding='same',activation='relu')(input_layer)\n",
        "    cnn = tfkl.AveragePooling1D()(cnn)\n",
        "    cnn = tfkl.Conv1D(512,3,padding='same',activation='relu')(cnn)\n",
        "    gap = tfkl.GlobalAveragePooling1D()(cnn)\n",
        "    dropout = tfkl.Dropout(.3, seed=seed)(gap)\n",
        "\n",
        "    # Classifier\n",
        "    classifier = tfkl.Dense(256, activation='relu')(dropout)\n",
        "    output_layer = tfkl.Dense(12, activation='softmax')(classifier)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model\n",
        "\n",
        "model = build_1DCNN_classifier(input_shape, classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "AuPbZ-mlfgEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=150, restore_best_weights=True)\n",
        "    ]\n",
        ").history"
      ],
      "metadata": {
        "id": "P6uolboTee70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d408cNUKV6pi"
      },
      "outputs": [],
      "source": [
        "best_epoch = np.argmax(history['val_accuracy'])\n",
        "plt.figure(figsize=(17,4))\n",
        "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Categorical Crossentropy')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(17,4))\n",
        "plt.plot(history['accuracy'], label='Training accuracy', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_accuracy'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the test set with the conv1D\n",
        "predictions = model.predict(X_val)\n",
        "predictions.shape"
      ],
      "metadata": {
        "id": "2EpRTFfHeZVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGdH9IVQfOd8"
      },
      "outputs": [],
      "source": [
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(cm.T, cmap='Blues')\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
